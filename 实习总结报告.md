# 实习总结报告

## 实习主要内容

实习期的主要内容是学习研究和AIOps有关的内容，前半段主要集中在异常检测上，后半段在更加熟悉这些内容之后主要在试图把各种曲线整合在一起，分类之后再进行检测。



### 异常检测

#### 主要思路

-----------------

针对这个问题看了一些km上的文章，也看了一些国外的方法，在有监督和无监督两种情况下，对于规律性较好的数据一般都能做得不错。

无监督情况下主要的做法是对于时间序列的每个点提取一些特征，特征可以是差值，例如和整个序列平均值的差值，或者和预测值的差值（这里预测也有多种方法），也可以是一些布尔值，例如浮动范围是否超过$3\sigma$等等。然后根据这些特征做离群检测，找出可能的异常点。

有监督情况下也是找特征，找到特征之后应用有监督的算法例如决策树或者神经网络，进行一定的训练之后就可以对之后的点进行预测。



#### 无监督学习

----------------------------------------

##### 算法、特征概览

关于无监督学习中算法的选择这里有几点值得注意：

- 由于最终实际上的测试是针对在线的数据，所以无监督学习里一些离群算法类似LOF是不可取的，因为它的原理本质在于寻找所有点集里面密度差异较大的那些点，作为异常点选出。所以每新进来一个数据，理论上我们就需要重新算一遍整个点集，可能比较费时间。
  - 这里有一个可能可行的猜测是，先针对历史数据做LOF，把标签打上，然后对于之后在线进来的数据直接做KNN。因为KNN和LOF一定程度上都是根据周围的点进行检测，所以也许可以保证一定的准确率。然后每天或者每周重新做一次LOF更新标签即可。
- 如果对于哪些特征有比较强的关联，哪些特征对于最终结果影响不大的判断不是很确定，都放进输入的话，我个人感觉所有和距离有关的离群算法都不会有很好的效果，因为无关特征会对距离产生贡献。如果假设我们把所有特征按照MinMax归一化（这应该是距离有关算法的前提），那么当无关特征的占比稍大，而且无关特征分布方差较大的时候距离就会受到很大的干扰。



所以我最终采取的做法是首先找出如下特征：

- 差值
  - 首先对于整个序列，求出平均值和标准差，随后计算每个点和平均值的差作为一个特征
  - 其次，对于整个序列应用Holt-Winter算法，或者也可以称作Triple Exponential Smooth，简而言之就是对于序列进行周期性、趋势的分解，计算出一个相对光滑的序列，并且对之后的结果做出预测。所以我们还获得了每个点相对于光滑曲线上对应时间点的差值。
- 布尔值
  - 对于每个点，我们考虑它是否超过了平均值附近$3,4,5$ $\sigma$的范围，如果是的话我们就标记为1，否则标为0。这里实际上我们是试图把传统的$3\sigma$的检测指标纳入进来。
  - 还有一个布尔值来自于Holt-Winter的波动范围。我们应用之前Holt-Winter求出的参数进行反向预测（这个做法有一个前提是整个时间序列可以比较干净地分解成趋势和周期的叠加，对于一些毛刺数据或者定时任务是肯定不行的），然后我们设定一个异常的比例$r$，根据这个比例我们二分法去看已经拿到的数据里，如果我设定一个范围$A$去挑异常，如果恰好能拿到$r$这个比例，我们就锁定这个A。然后把这个A应用到之后在线数据的异常上，同样标1或者0。

##### Holt-Winter

> Holt-Winter这种趋势分解的想法好像在近几年的研究中还比较常用，所以这里简单介绍一下怎么在程序里实现的。

对于一个给定的时间序列，我们的目标就是尽可能误差小地把曲线分解成一根倾斜直线加上一个周期函数。我们首先需要固定下来三个参数来告诉我们如何去分解这个序列（参数具体含义网上有介绍）。目标函数是分解后模拟出来的序列和原始序列差值的平方和，用梯度下降去找解即可。获得三个参数之后我们就可以根据网上的公式进行预测了。

下图是一个样例，蓝色是真实值，黄色是预测值，红色是异常点。

![holt-winter](C:\Users\tobyzxchen\Desktop\Work\holt-winter.png)

对于规律性比较好的数据，这种方式可以表现较好地预测出序列周期里的取值，而且过拟合的可能性很小，因为最后周期里的取值必须迎合历史的每一个周期。

但是这种方式在做预测的时候缺点也很明显，它的预测公式是

$X_t=L_t + (t+1)\times T_t + S_t[t\%p]$

其中$L_t​$相当于均值， $T_t​$ 相当于斜率，$S_t​$是一个数组，长度和周期相等。所以我们发现，建立在这种算法上的预测等于是默认了整个时间序列只包含一个==固定的单周期变化模式==。而且这个算法需要我们提前设定周期，对于正常的五分钟一个点的曲线，我们只要设个$T=288​$即可，但是对于一些曲线，比如周末上涨，或者按月份有规律的，就不能简单地做一次结束了。



==解决方法==

对于多个周期叠加的情况，理论上我们做多次Holt-Winter，每次`Input_ts = Input_ts - Pred_ts`即可。因为Holt-Winter只会输出固定的单周期值，所以不同频率的变化模式理论上会一直得以保留直到被选中，预测，减去。

我并没有实现这个想法，但我大概猜测了一下可能出现的问题和解决方法：

- 减掉一两个序列之后，剩下的序列值会比较小，导致异常数据点主宰了我们的目标函数（因为异常值波动大，对平方和的贡献也就比较大）
  - 一个初步的想法是拿到原始序列之后，我们设定一个异常比例比如$0.002$，这时候根据我们现有的算法，基本上可以筛选出一些肯定是异常的点，把他们用最近的正常点的平均值代换掉，这样就能一定程度上只保留曲线本身正常的特征。
  - 实际上我们可以在最开始就用$n\sigma$去筛选一下，我们就可以获得更加好的输入。



##### 遗留问题

关于特征的选取我觉得其实比较有争议。

> 首先不管是Isolation Forest还是LOF或者其他算法，无关特征一定会影响算法整体的表现。

在Isolation Forest里表现为改变所有点在树中的期望深度，导致异常点更加难以被区分（尤其是Isolation Forest为了更好的表现，每次建树只进行小范围的抽样，如果树的数量不足，无关特征数量太大，会干扰建树的步数，影响表现）。当然，如果每次抽样数量增加也会导致所有点的期望深度增加，所以这里是一个需要权衡的地方。

在我实际做的过程中，也试过加入一些简单的Moving Average相关的特征，结果整体算法的表现的确受到了一定的影响（判断依据主要是靠肉眼观察，有些短暂的幅度不太大的突出点被忽略了，于是整个算法的效果基本等于单纯的看$3\sigma$）。这里主要原因还是当数据本身具有周期性的时候，Moving Average的效果其实是完全不如Triple Smooth的，所以我们等于是使那些巨大异常点更加突出，剩下的点更加难以区分。

下面两个图分别是不加入和加入Moving Average的特征所得出的异常点（异常比例都设定为千分之五）。

![IForest_noMA](C:\Users\tobyzxchen\Desktop\Work\IForest_noMA.png)

![IForest_withMA](C:\Users\tobyzxchen\Desktop\Work\IForest_withMA.png)

可以看到，加入Moving Average之后我们可以检测到的异常点基本就等于是在单纯地筛选出偏离非常大的几个点，忽略了短暂的偏离小的点。

在实际情况下，我总共选取了不到十个特征，在周期性数据上的表现还可以，不过有时候会出现一些我看上去是错报的情况。但综合来看，这种方法比单纯地看$\sigma$或者单纯地用Triple Smooth效果是有明显提升的，所以我猜测这些特征都是具有很强关联性的特征。但是具体到最后应用的话还是应该更加仔细地挑选实验不同特征的效果。



> 但是关于Isolation Forest 和 LOF这样的算法对于所有特征集合的孰优孰劣没有肯定的结果，在规律性较好，特征选取得当的测试当中两者相差不大。
>
> 不过根据Isolation Forest提出的论文当中的测试，Isolation Forest在耗时，处理数据量的大小，稳定性等各方面都是目前主流的算法里数一数二的，并且很重要的一点是在加入大量无关特征之后仍然可以保持一定的分辨能力。





#### 有监督学习

----------------

我觉得在数据集有标签的情况下整个学习过程会比较轻松，因为不管是采用决策树还是神经网络这样的方法，都一定程度上可以自动忽略掉无关的特征，所以在特征的选取上我们可以大胆地输入几十个特征，如果我们的训练集有几千个点以上的话应该可以获得很好的结果。

不过我在实际实现当中还是用了之前无监督的那些特征，做Random Forest，效果也还可以。



### 曲线分类

#### 主要思路

------------------

对于曲线分类基本上还是无监督和有监督两种方式。

大体上还是去寻找曲线的一些特征，然后根据特征进行聚类（无监督），或者根据标签（有监督）运行一些类似决策树或者神经网络的算法。



#### 无监督学习

---------------------------

##### 算法、特征概览

算法方面可以选取一些比较常见的聚类算法，在`sklearn.cluster`里有一些已经实现的比较好的现成的库。

特征的选取相对而言比较复杂，描述一根曲线的特征有很多，比如最常见的平均值，中位数，标准差等等。但是具体到分类问题上，到底哪些特征有用哪些特征无用是非常难以判断的。



##### 难点

曲线分类这方面最主要的难点还是选取哪些特征，以及采用什么样的聚类算法。

实际上根据我个人的理解，各种无监督学习的算法实质上就是在模拟人类分类时的一些观察思考方法，在曲线分类里因为特征一般选的比较多，我们很难直接画出一个高维的点集，因此才选择用算法去分类，但是如果点集本身不具备很好的可分类性，再厉害的算法也没用。

而点集本身可分类性如何，又会极大地受选取特征的影响。因为我是看了一些网上的文章之后才开始做，所以我直接选取了一些常见的特征，包括平均值，中位数，标准差，Sample Entropy，线性趋势，偏度，峰度，自相似性，然后再加上一些针对性较强的，比如有多少比例的点是很低的值，或者很高的值等等

在选用这些特征的基础上我只实验了Birch和KMeans两种算法，总的来说聚类效果差别不太大，当把周期性好的数据和周期性不好的甚至是完全无规律的数据混合的时候，基本上曲线都可以按照形状被区分开来，不过周期性曲线会被分成好多类，肉眼比较难判断这些类别的区别。

同时，特征选取这方面还是一个需要考虑的因素，比如对于很多周期曲线，标准化之后平均值、标准差其实都差不多，再把它们加入聚类，或者乘以比较大的权重加进去可能反而会影响聚类的效果。这时候一些其他特征，比如`absolute_sum_of_changes = sum(abs(x[i+1]-x[i]))`可能反而可以把曲线比较好地分开来，但这个需要一些经验和比较多的尝试，如果只是比较粗糙地分类的话基本上直接扔进去十个常用的和几个针对性稍强的特征就足够了。

我看KM上有一个比较成体系的关于AIops的文章，他们选取了一百多个特征再进行聚类。我感觉如果他们的确是一步步从几个特征开始优化上去的，那么这当中耗费的人力应该是相当大的，因为普通的曲线特征很难描述出曲线之间形状的不同，需要自己设计大量的特征，而且代入不同的权重进行尝试。我个人感觉如果比较有经验的人来做，可以直接花一点时间，根据监测算法先打标记，就不需要一直尝试无监督学习了。



#### 有监督学习

-----------

还是如同异常检测一样，有监督的情况下特征的选取可以比较随意，应该不需要非常精细地排查无关特征或者效果不好的特征。

在曲线分类里我个人感觉比较好的做法是先尝试一些不同的聚类方式（用不同的特征+不同的算法），然后人工看一遍哪些曲线应该被归为一类可以给之后的检测提供便利，就打上一些标记，有了标记之后我们就可以后续地去建立一个决策树或者神经网络的模型，对所有曲线进行更好的分类。

有监督学习有一个比较好的地方在于通常可以给出一个概率分布，比如在异常检测的时候如果我们就设两个class，1代表异常，0代表正常，然后有一些标记之后我们建立了决策树（或者神经网络，输入输出的区别不是太大），那我们在线地拿进来一个新的点之后，就可以得到类似于`class 0: 85%, class 1:15%`这样的输出。

对曲线分类也是一样的，比如总共一万根曲线，我们人工地把其中一千根聚类效果好的标记到十个类别里，剩下的曲线就可以通过这个模型跑到各自的分类去，然后我们得到的输出也会是一个各个类别的概率分布。然后对于某根曲线，如果概率分布当中有某两三个类别的概率都比较高，我们就对它同时使用那些类别对应的检测方法，把结果加权综合成一个最终值，然后权重也可以根据反馈调节。



### 实验后的思路

-----



> 在经过一些对于各种思路和算法的尝试之后，我感觉有以下几个地方是和一开始想的不太一样的：

- 对于不能进行==线性趋势+周期==分解的曲线，几乎没有什么好办法去处理，因为异常检测最主要的还是去和历史数据进行对比，能做的比设上下限安全值更精细的应该避免不了需要一些预测，然后看和预测的偏差。我尝试了一下对没有周期的数据用LSTM去预测，但可能是因为我水平不够，尝试的网络的结构不够多，或者训练时间不够长，总的来说基本上预测不了。我看网上也有一些人尝试用LSTM去预测股票，效果也不行，对于检测的曲线来说虽然本身比股票的规律好很多，但是还是不太好做。总的来说这个方向还是有一定希望，但是需要投入比较大的精力尝试。
- 复杂的算法不一定能带来好的结果。我其实不管是检测还是分类都尝试了不少算法和特征，但是我最后基本上只用了几条很简单的规则去完成分类和检测，主要是我感觉目前而言所有的异常都是人眼可以判断的，人眼判断的依据其实也比较清楚，就是参照历史数据，看值的偏差和整个趋势的偏差。建立在这个基础上，其实复杂的算法本质上还是依赖于我们输入的特征，如果特征选的不好，算法再厉害也分辨不了异常，并且离群算法我们是无法进行直接的权重调节的，所以很难做到通过用户的反馈来改变权重。而如果我们把偏差量化一下，最后加权在一起，其实效果完全可以不输给一些离群算法，而且具备很好的根据反馈==自我调节==的能力。
  - 这一点的基础条件是异常点就是那些偏离大的点，其实还是很符合直观感觉的。但是如果对于某些指标，==偏离大的不一定是异常==，就需要一些特别的设计，这时候采用离群算法或者有监督学习效果会比较好。但是现在异常点的判断规则比较清晰，或者说主观因素比较强的时候，人为设置规则可能比较好。
  - 还有一点，因为我整个过程当中都是在考虑单根曲线的检测，所以相对来说简单的方法有时候更加方便准确（因为无监督学习的算法归根结底还是在试图模拟人的思考，而且往往模拟的没有那么好，所以人自己总结出来的规律做的比自动化的算法好也是合理的）。但是我猜测这个监测系统做的比较高级的时候应该有一些类似于==联动告警==的功能，比如我们把某十根曲线捆绑在一起，如果他们同时发生了细小的异常，就认为这是一个大异常，可以发出告警。如果要实现这样的功能的话，有监督学习应该是比较好的方式，但在没有标记的时候也完全可以用孤立森林去做，把每根曲线的偏差算出来两个特征，N根曲线就对应$2N$个特征，这样我们就有了一个大小为$T$, 维度是$2N$的点集，然后一起去做孤立森林就能得到一些结果了，如果采用的特征更多一些也是可以的。
  - 对于分类来说也是类似的，我还是觉得分类应该是要基于手里到底有什么样的监测算法。我目前能做的比较好的只有监测具有周期性的数据，然后对于周期性不好的基本上就只能设计一些非常粗糙的安全值的监测方式，所以其实只根据少量的特征去按要求分类的效果反而会比无监督多特征的聚类要好。



> 我最后的做法：

分类：

1. 拿到一根曲线之后我先计算了一个自己定义的`Bf_period`（暴力周期）值，这个值反映的是一根曲线对$288$（五分钟一个点， 周期为一天）这个周期的不符合程度，一般输入的时间长度在$3000$个点（一周）的时候这个值就比较稳定了。一个纯粹的正态分布的误差，这个值应该是$0.01$
2. 然后根据这个值，筛选出低于0.005的曲线，认为他们的周期性很好，直接去跑周期预测的那个监测方法就行。对大于0.008的曲线，基本可以认定它们的周期性很差，要么就是肉眼可以看出周期，但是周期内震荡很剧烈，要么就是完全没有周期。对介于0.005和0.008之间的曲线，大部分是肉眼可以看出明显的周期性，但是往往每个周期和预测值都有比较大的偏差，用普通的预测方式不一定能预测很准（基本上表现为报出很多告警，但实际上部分告警应该都是正常的值），所以可能需要再加一些处理，或者在给出告警的时候分个优先级之类的。
3. 对大于0.008的曲线，我们可以按形状进行聚类，然后人工地打上一些标记，训练一个模型出来。具体分类大概是：我们可以筛选出一批可以看出周期的曲线，我们可以对它们进行一些只关注形状偏离+安全值的监测方式。对于没有周期性的曲线，我们可以筛选出一批平滑直线+一个大凸起/一个大坑形状的曲线，对他们设计一个监测方法。剩下的曲线我们基本就按照设定上下限的方式简单地去处理了。我先用了一个聚类算法，把这些曲线提取出来大约十几个特征，按照形状自动分类。然后把我认为和监督方法对应的类别划分到同一类，打上标记，然后再把这些标记和特征放回去做一次决策树，得到一个之后可以在线使用的模型。



监测：

1. Stable: 对于0.005以下的曲线，监测的方法就是根据历史数据进行预测，因为周期性很好，所以可以比较轻松地预测出未来一天的值。对于偏差比较大的点，有可能是因为值在那个时间段本身就应该有比较大的变化，所以如果偏离预测值比较大，就再检查一下这个点在时间轴上向左向右离正常范围的距离，如果在前后半小时内这个值出现是正常的，我就认为它现在出现也是正常的。
2. Sharp: 对于0.005以上的周期性曲线，比较经常出现的情况就是周期的最大最小值相差较大，或者在周期内有幅度比较大的波动，我暂时没有想到特别针对性的办法去做，大致上就是把值偏差和形状偏差的允许范围相对情况1调大一点。
3. Keng: 对于大坑型数据，我们只需要找到一根基准线，然后大坑的时候报异常就行，我偷懒还是用了周期分解，因为大坑持续时间不长，基本不会影响周期的平均值，所以用相同的办法分解完就可以直接得到基准的值
4. Safe: 剩下的曲线我直接叫safe，因为没有很好的规律，根据历史数据按异常比例设定一个安全值即可。

![_0_5_28_67848](C:\Users\tobyzxchen\Desktop\_0_5_28_67848.png)

![_0_4_34_67078](C:\Users\tobyzxchen\Desktop\_0_4_34_67078.png)

![_0_4_30_73472 (2)](C:\Users\tobyzxchen\Desktop\_0_4_30_73472 (2).png)

![_0_4_30_71945](C:\Users\tobyzxchen\Desktop\_0_4_30_71945.png)

![_0_5_28_70656 (2)](C:\Users\tobyzxchen\Desktop\_0_5_28_70656 (2).png)

![_0_4_28_67594 (2)](C:\Users\tobyzxchen\Desktop\_0_4_28_67594 (2).png)

![_0_4_30_70912 (2)](C:\Users\tobyzxchen\Desktop\_0_4_30_70912 (2).png)

![_0_5_28_66574 (2)](C:\Users\tobyzxchen\Desktop\_0_5_28_66574 (2).png)

![_0_5_34_67594 (2)](C:\Users\tobyzxchen\Desktop\_0_5_34_67594 (2).png)

上面是一千多条曲线里随机抽取的，主要展示一下大概的效果。这些曲线都是只输入一个`timestamp + value`的表格之后直接输出的。



### 总结

虽然我最后采用的方法都比较简单，但是整个过程当中我做了不少尝试，大部分网上提到的算法、模型都实现过，最终我还是觉得就手里的数据而言，简单的方法可以得到更好的效果。而且我觉得很多场景下不同算法的差距不大，更难的还是在于如何处理数据以及如何提取有效的特征，尤其是在无监督的情况下，如果有比较多的判断异常的经验，这个东西就会比较好做。

同时，无监督学习相比有监督学习应该是难很多的，如果我们可以积累一段时间标记好异常的数据，然后再进行曲线分类，对不同类别的曲线建立针对性的模型（主要是特征要有针对性，比如没有周期性的数据就不需要再去计算任何周期相关的特征），我们这个东西超越其他平台指日可待。